{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Imaging - Pneunomia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import shutil\n",
    "import urllib.request\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, \\\n",
    "  GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, \\\n",
    "  preprocess_input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, \\\n",
    "  ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from itertools import product\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Location\n",
    "train_dir = \"./train\"\n",
    "validation_dir = \"./val\"\n",
    "test_dir = \"./test\"\n",
    "\n",
    "# Check if we can access the images\n",
    "example_img = mpimg.imread(train_dir + \"/NORMAL/IM-0115-0001.jpeg\")\n",
    "plt.imshow(example_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building The Model Using InceptionV3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "\n",
    "def create_model(input_shape):\n",
    "  base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "  \n",
    "  x = base_model.output\n",
    "  x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "  x = Dense(512, activation='relu')(x)\n",
    "  x = Dropout(0.3)(x)\n",
    "  x = Dense(256, activation='relu')(x)\n",
    "  x = Dropout(0.3)(x)\n",
    "  x = Dense(128, activation='relu')(x)\n",
    "  x = Dropout(0.3)(x)\n",
    "  \n",
    "  for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "  predictions = Dense(NUM_CLASSES, activation='sigmoid')(x)\n",
    "  model = Model(inputs=base_model.inputs, outputs=predictions)\n",
    "  return model\n",
    "\n",
    "model = create_model((150, 150, 3))\n",
    "\n",
    "training_loss = tf.keras.metrics.Mean('training_loss', dtype=tf.float32)\n",
    "training_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    'training_accuracy', dtype=tf.float32)\n",
    "test_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    'test_accuracy', dtype=tf.float32)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.0001)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer, \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale = 1./255\n",
    "target_size = (150, 150)\n",
    "batch_size = 163\n",
    "class_mode = 'categorical'\n",
    "\n",
    "\n",
    "def dir_file_count(directory):\n",
    "    return sum([len(files) for r, d, files in os.walk(directory)])\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=rescale,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   validation_split=0.2)\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=target_size,\n",
    "                                                    class_mode=class_mode,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=rescale)\n",
    "val_generator = val_datagen.flow_from_directory(validation_dir, \n",
    "                                                target_size=target_size,\n",
    "                                                class_mode=class_mode,\n",
    "                                                batch_size=dir_file_count(validation_dir),\n",
    "                                                shuffle=False)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=rescale)\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "                                                  target_size=target_size,\n",
    "                                                  class_mode=class_mode,\n",
    "                                                  batch_size=dir_file_count(test_dir),\n",
    "                                                  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_generator.classes\n",
    "labels = np.unique(y)\n",
    "\n",
    "train_class_weights = compute_class_weight('balanced', labels, y)\n",
    "print(train_class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=len(train_generator),\n",
    "                              epochs=100,\n",
    "                              verbose=1,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=len(val_generator),\n",
    "                              class_weight=train_class_weights,\n",
    "                              workers=20)\n",
    "\n",
    "MODEL_FILE = 'pneumonia_v0.0.1.hd5'\n",
    "model.save(MODEL_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabel = 'Epoch'\n",
    "legends = ['Training', 'Validation']\n",
    "\n",
    "ylim_pad = [0.01, 0.1]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot training & validation Accuracy values\n",
    "\n",
    "y1 = history.history['acc']\n",
    "y2 = history.history['val_acc']\n",
    "\n",
    "min_y = min(min(y1), min(y2))-ylim_pad[0]\n",
    "max_y = max(max(y1), max(y2))+ylim_pad[0]\n",
    "\n",
    "\n",
    "plt.subplot(121)\n",
    "\n",
    "plt.plot(y1)\n",
    "plt.plot(y2)\n",
    "\n",
    "plt.title('Model Accuracy', fontsize=17)\n",
    "plt.xlabel(xlabel, fontsize=15)\n",
    "plt.ylabel('Accuracy', fontsize=15)\n",
    "plt.ylim(min_y, max_y)\n",
    "plt.legend(legends, loc='upper left')\n",
    "plt.grid()\n",
    "\n",
    "                         \n",
    "# Plot training & validation loss values\n",
    "    \n",
    "y1 = history.history['loss']\n",
    "y2 = history.history['val_loss']\n",
    "\n",
    "min_y = min(min(y1), min(y2))-ylim_pad[1]\n",
    "max_y = max(max(y1), max(y2))+ylim_pad[1]\n",
    "    \n",
    "    \n",
    "plt.subplot(122)\n",
    "\n",
    "plt.plot(y1)\n",
    "plt.plot(y2)\n",
    "\n",
    "plt.title('Model Loss', fontsize=17)\n",
    "plt.xlabel(xlabel, fontsize=15)\n",
    "plt.ylabel('Loss', fontsize=15)\n",
    "plt.ylim(min_y, max_y)\n",
    "plt.legend(legends, loc='upper left')\n",
    "plt.grid()\n",
    "                         \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(MODEL_FILE)\n",
    "\n",
    "result = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\n",
    "print(\"%s%.2f  \"% (\"Loss     : \", result[0]))\n",
    "print(\"%s%.2f%s\"% (\"Accuracy : \", result[1]*100, \"%\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_generator(test_generator, steps=len(test_generator), verbose=1)  \n",
    "y_pred = y_pred.argmax(axis=-1)\n",
    "y_true = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "num_of_batch = len(test_generator)\n",
    "batch_no = random.randint(0, num_of_batch - 1)\n",
    "\n",
    "y_img_batch, y_true_batch = test_generator.__getitem__(batch_no)\n",
    "y_true_batch = y_true_batch.argmax(axis=-1)\n",
    "\n",
    "y_pred_batch = model.predict(y_img_batch)\n",
    "y_pred_batch = y_pred_batch.argmax(axis=-1)\n",
    "\n",
    "print(\"-\"*35)\n",
    "print(\"%s%d\"%     (\"Selected Batch No       : \", batch_no))\n",
    "print(\"-\"*35)\n",
    "print(\"%s%d\"%     (\"Batch Size              : \", len(y_pred_batch)))\n",
    "print(\"-\"*35)\n",
    "print(\"%s%.2f%s\"% (\"Accuracy                : \", np.mean(y_true==y_pred)*100, \"%\"))\n",
    "print(\"-\"*35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "filenames = test_generator.filenames\n",
    "nb_samples = np.ceil(nb_samples/len(filenames))\n",
    "\n",
    "predict = model.predict_generator(test_generator, steps=nb_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "predicted_class_indices = np.argmax(predict, axis=1)\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "filenames = test_generator.filenames\n",
    "results = pd.DataFrame({\"Filename\": filenames,\n",
    "                        \"Predictions\": predictions})\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
